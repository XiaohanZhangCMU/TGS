{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inherit Dataset Class of Torchvision for TGS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TGS_Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, input_fpaths, train=True, download=False):\n",
    "        super()\n",
    "\n",
    "        train_ids = next(os.walk(train_dir+\"images\"))[2]\n",
    "        test_ids  = next(os.walk(test_dir+\"images\"))[2]                \n",
    "        self.ids = ids\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        id = self.ids[index]\n",
    "        folder, name   = id.split('/')\n",
    "        image = cv2.imread(DATA_DIR + '/image/%s/images/%s.png'%(folder,name), cv2.IMREAD_COLOR)\n",
    "\n",
    "        if self.mode in ['train']:\n",
    "            mask = np.load( DATA_DIR + '/image/%s/masks/%s.npy'%(folder,name)).astype(np.int32)\n",
    "            if self.transform is not None:\n",
    "                return self.transform(image, mask, index)\n",
    "            else:\n",
    "                return image, mask, index\n",
    "\n",
    "        if self.mode in ['test']:\n",
    "            if self.transform is not None:\n",
    "                return self.transform(image, index)\n",
    "            else:\n",
    "                return image, index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unitest for dataset reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_check_train_dataset_reader():\n",
    "\n",
    "    dataset = ScienceDataset(\n",
    "        'train1_ids_gray2_500',\n",
    "        #'disk0_ids_dummy_9',\n",
    "        #'merge1_1',\n",
    "        mode='train',transform = None,\n",
    "    )\n",
    "\n",
    "    for n in range(len(dataset)):\n",
    "        i=n #13  #=\n",
    "        image, mask_truth, index = dataset[i]\n",
    "\n",
    "        folder, name = dataset.ids[index].split( '/')\n",
    "        print('%05d %s' %(i,name))\n",
    "\n",
    "        # image1 = random_transform(image, u=0.5, func=process_gamma, gamma=[0.8,2.5])\n",
    "        # image2 = process_gamma(image, gamma=2.5)\n",
    "\n",
    "        #image1 = random_transform(image, u=0.5, func=do_process_custom1, gamma=[0.8,2.5],alpha=[0.7,0.9],beta=[1.0,2.0])\n",
    "        #image1 = random_transform(image, u=0.5, func=do_unsharp, size=[9,19], strength=[0.2,0.4],alpha=[4,6])\n",
    "        #image1 = random_transform(image, u=0.5, func=do_speckle_noise, sigma=[0.1,0.5])\n",
    "\n",
    "        #image1, truth_mask1 = random_transform2(image, truth_mask, u=0.5, func=do_shift_scale_rotate2, dx=[0,0],dy=[0,0], scale=[1/2,2], angle=[-45,45])\n",
    "        #image1, truth_mask1 = random_transform2(image, truth_mask, u=0.5, func=do_elastic_transform2, grid=[16,64], distort=[0,0.5])\n",
    "\n",
    "\n",
    "\n",
    "        # image_show('image',image,1)\n",
    "        # color_overlay = mask_to_color_overlay(truth_mask)\n",
    "        # image_show('color_overlay',color_overlay,1)\n",
    "        #\n",
    "        #\n",
    "        # image_show('image1',image1,1)\n",
    "        # #image_show('image2',image2,1)\n",
    "        # color_overlay1 = mask_to_color_overlay(truth_mask1)\n",
    "        # image_show('color_overlay1',color_overlay1,1)\n",
    "\n",
    "\n",
    "        label_truth = mask_to_annotation(mask_truth)\n",
    "\n",
    "        contour_overlay = mask_to_contour_overlay(mask_truth,  image, [0,255,0])\n",
    "        image_show('contour_overlay',contour_overlay,resize=1)\n",
    "\n",
    "\n",
    "        image_show_norm('label_truth',label_truth,resize=1)\n",
    "        # image_show_norm('truth_foreground',truth_foreground,resize=1)\n",
    "        # image_show_norm('truth_border',truth_border,resize=1)\n",
    "        cv2.waitKey(0)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function entry for test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print( '%s: calling main function ... ' % os.path.basename(__file__))\n",
    "\n",
    "    run_check_train_dataset_reader()\n",
    "\n",
    "    print( 'sucess!')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
